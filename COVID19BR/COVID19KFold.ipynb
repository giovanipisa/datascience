{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0d3461-6a09-4fb8-a827-797a6bcaa0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.9122807017543859, 0.9473684210526315, 0.9736842105263158, 0.9736842105263158, 0.9557522123893806]\n",
      "Avg accuracy : 0.952553951249806\n"
     ]
    }
   ],
   "source": [
    "# https://www.askpython.com/python/examples/k-fold-cross-validation\n",
    "# K-fold Cross Validation using scikit learn\n",
    "#Importing required libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    " \n",
    "#Loading the dataset\n",
    "data = load_breast_cancer(as_frame = True)\n",
    "df = data.frame\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    " \n",
    "#Implementing cross validation\n",
    " \n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "model = LogisticRegression(solver= 'liblinear')\n",
    " \n",
    "acc_score = []\n",
    " \n",
    "for train_index , test_index in kf.split(X):\n",
    "    \n",
    "    X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "    y_train , y_test = y[train_index] , y[test_index]\n",
    "     \n",
    "    model.fit(X_train,y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "     \n",
    "    acc = accuracy_score(pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    " \n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08597023-ad56-4e6b-a4b9-c0ab98ba7cb3",
   "metadata": {},
   "source": [
    "### **************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b17b5f-e1ba-4a50-a0a0-304402b705f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer \n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec7420d-4baf-4e5c-9f18-4ed917e72ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72606144-a767-4248-8d1c-7dac30d04560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando o dataset COVID19BR\n",
    "\n",
    "dados = pd.read_csv('covidbr_labeled.csv')\n",
    "#dados.head()\n",
    "X = dados['text']\n",
    "y = dados['misinformation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0b2675-854b-45ee-8c66-f006b4547b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_por = set(stopwords.words(\"portuguese\"))\n",
    "def limpa_texto(string):\n",
    "    text = string.lower().split()\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"http(\\S)+\",' ',text)    \n",
    "    text = re.sub(r\"www(\\S)+\",' ',text)\n",
    "    text = re.sub(r\"&\",' and ',text)  \n",
    "    tx   = text.replace('&amp',' ')\n",
    "    text = re.sub(r\"[^0-9a-zA-Z]+\",' ',text)\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stop_por]\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc65383-2cfc-45ed-b17e-fc4a5f6950d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.map(lambda x: limpa_texto(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cfde45-ab79-433e-8a72-6af27d38d67f",
   "metadata": {},
   "source": [
    "# Início do tutorial encontrado em:\n",
    "https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.Y1Ccl3bMJPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "daaeab7b-b8c1-4ff5-b874-ac75fbd0c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#instantiate CountVectorizer() \n",
    "cv=CountVectorizer() \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector=cv.fit_transform(X) # o X são as postagens do meu arquivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0aef0079-8999-4b1a-b324-a7cc0ce70228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2898, 21262)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb829f69-6884-47f8-a557-5bd62b8e6c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff89914-56c4-4e0b-a765-2f11099ac701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print idf values \n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "849c99aa-0e86-440c-8174-02f479d5bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count matrix \n",
    "count_vector=cv.transform(X) \n",
    "# tf-idf scores \n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5744d71-c311-4f8c-a201-61e3641e1bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names() \n",
    "#get tfidf vector for first document \n",
    "first_document_vector=tf_idf_vector[0] \n",
    "#print the scores \n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "867f178a-986a-433d-8964-e17439bfa6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# settings that you use for count vectorizer will go here \n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True) \n",
    "# just send in all your docs here \n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "616f62b7-ce7a-451d-92fd-fcb6557350aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>testes</th>\n",
       "      <td>0.236319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verm</th>\n",
       "      <td>0.202577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fugo</th>\n",
       "      <td>0.202577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomografia</th>\n",
       "      <td>0.202577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fosco</th>\n",
       "      <td>0.202577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desviei</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desviar</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desviando</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>desviamos</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zumbis</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21262 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf\n",
       "testes      0.236319\n",
       "verm        0.202577\n",
       "fugo        0.202577\n",
       "tomografia  0.202577\n",
       "fosco       0.202577\n",
       "...              ...\n",
       "desviei     0.000000\n",
       "desviar     0.000000\n",
       "desviando   0.000000\n",
       "desviamos   0.000000\n",
       "zumbis      0.000000\n",
       "\n",
       "[21262 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first vector out (for the first document) \n",
    "first_vector_tfidfvectorizer=tfidf_vectorizer_vectors[0] \n",
    "# place tf-idf values in a pandas data frame \n",
    "df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), \n",
    "                  index=tfidf_vectorizer.get_feature_names(), \n",
    "                  columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9b5b894-9bb2-4825-bacd-ead696641b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pode ser resumido nisto: \n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "# just send in all your docs here\n",
    "fitted_vectorizer=tfidf_vectorizer.fit(X)\n",
    "tfidf_vectorizer_vectors=fitted_vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea3daa-8dfd-44d2-96c3-2692946d0039",
   "metadata": {},
   "source": [
    "# Fim do tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329b3cb7-0b5b-4c9b-9e7e-974e5016c8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificar o resultado da limpeza do texto\n",
    "contador = 0\n",
    "for i in X:\n",
    "    contador += 1\n",
    "    print(i)\n",
    "    if contador > 5:\n",
    "        stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678290c2-3b41-43fb-8b4e-2cfc8f70e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('bow', CountVectorizer()),  \n",
    "        ('tfidf', TfidfTransformer()),  \n",
    "        ('c', LogisticRegression())\n",
    "    ])\n",
    "fit = pipeline.fit(treino['text'],treino['misinformation'])\n",
    "print('Logistic Regression')\n",
    "print ('val:')\n",
    "pred=pipeline.predict(validacao['text'])\n",
    "imprime_metricas(pred,validacao['misinformation'])\n",
    "plota_matriz_de_confusao(confusion_matrix(validacao['misinformation'],pred),\n",
    "                         target_names=['Falso','Verdadeiro'], \n",
    "                         normalize = False,\n",
    "                         title = 'Matriz de confusão Regressão Logística: COVID19BR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38126ff3-43e7-4a54-8f48-1d87ebc2f230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.8364389233954451, 0.7670807453416149, 0.8136645962732919]\n",
      "Avg accuracy : 0.8057280883367839\n"
     ]
    }
   ],
   "source": [
    "X_ = tfidf_vectorizer_vectors\n",
    "\n",
    "#Implementando a validação cruzada\n",
    " \n",
    "k = 3\n",
    "kf = KFold(n_splits=k, random_state=None)\n",
    "model = LogisticRegression(solver= 'liblinear')\n",
    " \n",
    "acc_score = []\n",
    " \n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X_[train_index],X_[test_index]\n",
    "    y_train , y_test = y[train_index],y[test_index]\n",
    "     \n",
    "    model.fit(X_train,y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "     \n",
    "    acc = accuracy_score(pred_values , y_test)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    " \n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
